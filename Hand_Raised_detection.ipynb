{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NpVIFd7SgSUu",
        "outputId": "2100c33f-73a4-4bff-ad22-91948de2ac5e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ultralytics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s1t8Zkvkhg_q",
        "outputId": "53dc74ae-e740-4ba5-bf1f-4d920d774a97"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.3.49-py3-none-any.whl.metadata (35 kB)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.26.4)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.8.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.10.0.84)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (11.0.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.13.1)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.5.1+cu121)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.20.1+cu121)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.66.6)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.2.2)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.13.2)\n",
            "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.13-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.55.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2024.8.30)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
            "Downloading ultralytics-8.3.49-py3-none-any.whl (898 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m898.7/898.7 kB\u001b[0m \u001b[31m51.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.13-py3-none-any.whl (26 kB)\n",
            "Installing collected packages: ultralytics-thop, ultralytics\n",
            "Successfully installed ultralytics-8.3.49 ultralytics-thop-2.0.13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "dataset_path = '/content/drive/MyDrive/Hand/custom.yaml'\n",
        "\n",
        "model = YOLO('yolov8n.pt')\n",
        "\n",
        "model.train(\n",
        "    data=dataset_path,  # Path to the data.yaml\n",
        "    epochs=50,            # Number of training epochs\n",
        "    imgsz=768,            # Image size for training\n",
        "    batch=8,             # Batch size\n",
        "    name='yolov8_training',  # Name of the training run\n",
        "    device=0              # Use GPU if available\n",
        ")\n",
        "\n",
        "\n",
        "results = model.val()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "abuRe1ahgdBW",
        "outputId": "65fa1462-61bf-4d1a-8c36-02932ba64643"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating new Ultralytics Settings v0.0.6 file âœ… \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n",
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8n.pt to 'yolov8n.pt'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6.25M/6.25M [00:00<00:00, 253MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.49 ğŸš€ Python-3.10.12 torch-2.5.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=/content/drive/MyDrive/Hand/custom.yaml, epochs=50, time=None, patience=100, batch=8, imgsz=768, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=yolov8_training, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/yolov8_training\n",
            "Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 755k/755k [00:00<00:00, 123MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overriding model.yaml nc=80 with nc=1\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1    751507  ultralytics.nn.modules.head.Detect           [1, [64, 128, 256]]           \n",
            "Model summary: 225 layers, 3,011,043 parameters, 3,011,027 gradients, 8.2 GFLOPs\n",
            "\n",
            "Transferred 319/355 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/yolov8_training', view at http://localhost:6006/\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5.35M/5.35M [00:00<00:00, 234MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/Hand/labels/train... 33 images, 29 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 62/62 [01:23<00:00,  1.35s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/drive/MyDrive/Hand/labels/train.cache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/albumentations/__init__.py:24: UserWarning: A new version of Albumentations is available: 1.4.22 (you have 1.4.20). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
            "  check_for_updates()\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/Hand/labels/val... 10 images, 0 backgrounds, 1 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:15<00:00,  1.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /content/drive/MyDrive/Hand/images/val/frame028.jpg: ignoring corrupt image/label: negative label values [  -0.025308]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/drive/MyDrive/Hand/labels/val.cache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Plotting labels to runs/detect/yolov8_training/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added âœ…\n",
            "Image sizes 768 train, 768 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/detect/yolov8_training\u001b[0m\n",
            "Starting training for 50 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       1/50      1.64G      2.183      8.403      1.434          6        768: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:07<00:00,  1.05it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.57s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          9          9    0.00333          1    0.00484    0.00209\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       2/50      1.58G       2.12      6.542      1.299          7        768: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.94it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  5.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          9          9    0.00333          1    0.00574    0.00321\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       3/50      1.64G       1.88      5.662      1.247          2        768: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.38it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          9          9    0.00333          1    0.00659    0.00323\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       4/50      1.63G      1.799      4.191      1.186         15        768: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.43it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  3.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          9          9    0.00296      0.889    0.00577    0.00361\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       5/50      1.58G      1.788      4.316      1.139          4        768: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  6.31it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 10.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          9          9    0.00296      0.889    0.00593    0.00299\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       6/50      1.64G        1.8      4.037      1.238          7        768: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.90it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          9          9    0.00296      0.889    0.00802    0.00339\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       7/50      1.63G      1.823      3.795        1.2          6        768: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  6.20it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  5.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          9          9    0.00296      0.889      0.212      0.124\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       8/50      1.58G      1.819       5.21      1.128          5        768: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  6.07it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          9          9    0.00296      0.889     0.0697     0.0507\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       9/50      1.63G      1.642      3.631      1.089          5        768: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.65it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          9          9    0.00296      0.889      0.828      0.503\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      10/50      1.58G      1.557      3.351      1.116          5        768: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.04it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          9          9    0.00333          1      0.608      0.315\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      11/50      1.64G      1.682      3.141       1.14          7        768: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.45it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  3.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          9          9    0.00333          1      0.438      0.244\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      12/50      1.64G      1.766      4.374      1.186          6        768: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  6.05it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 10.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          9          9      0.728      0.667      0.698      0.413\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      13/50      1.64G      1.684      3.044      1.132          8        768: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  6.35it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  7.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          9          9      0.693      0.556      0.795      0.524\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      14/50      1.64G       1.43      2.773      1.037          7        768: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.87it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  6.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          9          9      0.793      0.856      0.827      0.386\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      15/50      1.64G      1.569      3.292      1.092          6        768: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  6.24it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 10.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          9          9      0.797      0.873       0.81      0.395\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      16/50      1.64G      1.499       2.69      1.123          5        768: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  6.82it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  3.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          9          9      0.887      0.874      0.801       0.45\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      17/50      1.64G      1.572      3.397      1.169          5        768: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.24it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  3.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          9          9      0.889      0.886        0.8      0.457\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      18/50      1.64G      1.436       2.69      1.035          5        768: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.50it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          9          9      0.879      0.889      0.824      0.445\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      19/50      1.64G      1.502      3.083      1.166          3        768: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  6.19it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  7.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          9          9      0.873      0.889      0.873       0.39\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      20/50      1.64G      1.426      2.431      1.075          9        768: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  6.76it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  5.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          9          9          1      0.874      0.885      0.449\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      21/50      1.64G      1.468      2.582       1.05          6        768: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  6.14it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  7.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          9          9      0.863      0.889      0.873      0.535\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      22/50      1.64G      1.421      2.315      1.014         11        768: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.87it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          9          9      0.873      0.889      0.873      0.587\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      23/50      1.64G      1.431      2.837      1.184          9        768: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.65it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  6.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          9          9      0.875      0.889      0.873      0.597\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      24/50      1.64G      1.438      2.879      1.122          5        768: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.06it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  5.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          9          9       0.88      0.889      0.873      0.539\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      25/50      1.64G      1.345      2.464      1.039          5        768: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.42it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  3.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          9          9      0.877      0.889      0.873      0.574\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      26/50      1.64G      1.313      2.083      1.028          5        768: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.45it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          9          9      0.882      0.889      0.861      0.551\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      27/50      1.64G      1.369      3.082      1.082          7        768: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.52it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  3.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          9          9      0.881      0.889      0.873      0.556\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      28/50      1.64G      1.322       2.14      1.166          3        768: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.84it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  7.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          9          9      0.879      0.889      0.873      0.557\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      29/50      1.64G       1.33      2.101       1.06          9        768: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.73it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  6.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          9          9      0.882      0.889      0.925      0.588\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      30/50      1.64G      1.312      2.382      1.043          3        768: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.39it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  6.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          9          9      0.885      0.889      0.918        0.6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      31/50      1.64G      1.191      1.773     0.9798          5        768: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.95it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  5.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          9          9      0.888      0.879      0.861      0.615\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      32/50      1.64G      1.259      1.705      1.014          6        768: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.43it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  6.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          9          9      0.889      0.888      0.849      0.605\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      33/50      1.64G      1.188      1.922      1.074          9        768: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  6.12it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  5.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          9          9      0.886      0.889      0.837      0.613\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      34/50      1.64G      1.114      1.838     0.9937          5        768: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.68it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 11.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          9          9      0.884      0.889      0.861      0.634\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      35/50      1.64G      1.265      1.734      1.018          6        768: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  6.08it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  7.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          9          9      0.875      0.889      0.861      0.635\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      36/50      1.64G      1.091      1.823     0.9477          5        768: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  6.09it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 11.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          9          9      0.874      0.889      0.861      0.631\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      37/50      1.64G       1.12      1.831     0.9995          5        768: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.65it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  7.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          9          9      0.872      0.889      0.873      0.639\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      38/50      1.64G      1.086      1.612     0.9821          7        768: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.94it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          9          9      0.872      0.889      0.873      0.645\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      39/50      1.64G      1.113      1.666      1.018          8        768: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.01it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  7.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          9          9      0.883      0.889      0.849      0.619\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      40/50      1.64G      1.165       1.79      1.018          5        768: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  6.14it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  6.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          9          9      0.883      0.889      0.837      0.609\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      41/50      1.64G      1.055      2.322      1.011          3        768: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.83it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          9          9      0.883      0.889      0.837      0.596\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      42/50      1.64G      1.163      2.511      1.041          3        768: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.03it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  6.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          9          9      0.882      0.889      0.837      0.582\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      43/50      1.64G       1.02      2.317      0.963          1        768: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.82it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  3.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          9          9      0.882      0.889      0.837      0.605\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      44/50      1.64G      1.052      2.414      1.038          4        768: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.56it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  3.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          9          9      0.882      0.889      0.861      0.639\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      45/50      1.64G      1.006      2.277      1.042          3        768: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.97it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          9          9      0.882      0.889      0.861      0.648\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      46/50      1.64G      1.098      2.695     0.9604          3        768: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  6.66it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  6.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          9          9      0.883      0.889      0.873      0.642\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      47/50      1.64G     0.9529      2.108      1.003          3        768: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  6.21it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          9          9      0.883      0.889      0.873       0.63\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      48/50      1.64G      1.068      2.359     0.9755          3        768: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  6.41it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  6.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          9          9      0.883      0.889      0.873      0.629\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      49/50      1.64G     0.9705      2.122      0.992          2        768: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.67it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  7.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          9          9      0.883      0.889      0.873      0.662\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      50/50      1.64G     0.9609      2.218      1.019          4        768: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.04it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          9          9      0.883      0.889      0.873      0.657\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "50 epochs completed in 0.041 hours.\n",
            "Optimizer stripped from runs/detect/yolov8_training/weights/last.pt, 6.2MB\n",
            "Optimizer stripped from runs/detect/yolov8_training/weights/best.pt, 6.2MB\n",
            "\n",
            "Validating runs/detect/yolov8_training/weights/best.pt...\n",
            "Ultralytics 8.3.49 ğŸš€ Python-3.10.12 torch-2.5.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "Model summary (fused): 168 layers, 3,005,843 parameters, 0 gradients, 8.1 GFLOPs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  7.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          9          9      0.883      0.889      0.873      0.659\n",
            "Speed: 0.2ms preprocess, 3.8ms inference, 0.0ms loss, 2.1ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/yolov8_training\u001b[0m\n",
            "Ultralytics 8.3.49 ğŸš€ Python-3.10.12 torch-2.5.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "Model summary (fused): 168 layers, 3,005,843 parameters, 0 gradients, 8.1 GFLOPs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/Hand/labels/val.cache... 10 images, 0 backgrounds, 1 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /content/drive/MyDrive/Hand/images/val/frame028.jpg: ignoring corrupt image/label: negative label values [  -0.025308]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  3.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          9          9      0.883      0.889      0.873      0.659\n",
            "Speed: 0.7ms preprocess, 25.8ms inference, 0.0ms loss, 2.2ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/yolov8_training2\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# Step 1: Load the YOLO model\n",
        "model_path = \"/content/drive/MyDrive/Hand/best.pt\"\n",
        "model = YOLO(model_path)\n",
        "\n",
        "# Step 2: Open the video file\n",
        "video_path = \"/content/drive/MyDrive/Hand/desk_video.mp4\"\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "if not cap.isOpened():\n",
        "    raise ValueError(\"Error opening video file\")\n",
        "\n",
        "# Get video properties\n",
        "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
        "\n",
        "# Prepare the output video writer\n",
        "output_path = \"/content/drive/MyDrive/Hand/output_video_with_person_identification.mp4\"\n",
        "fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
        "out = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))\n",
        "\n",
        "# Step 3: Define the ranges and mapping function\n",
        "ranges = [\n",
        "    {\"object\": \"Tanvir Vai\", \"x_range\": (550, 570), \"y_range\": (450, 485)},\n",
        "    {\"object\": \"Anik Vai\", \"x_range\": (1130, 1150), \"y_range\": (450, 465)},\n",
        "    {\"object\": \"Toufiq Vai\", \"x_range\": (795, 880), \"y_range\": (450, 461)},\n",
        "    {\"object\": \"Imran Vai\", \"x_range\": (1135, 1160), \"y_range\": (470, 520)},\n",
        "    {\"object\": \"Murfad Vai\", \"x_range\": (955, 995), \"y_range\": (470, 495)},\n",
        "    {\"object\": \"Emon Vai\", \"x_range\": (1210, 1230), \"y_range\": (475, 505)},\n",
        "    {\"object\": \"Shafayet Vai\", \"x_range\": (700, 720), \"y_range\": (465, 485)},\n",
        "    {\"object\": \"Faisal Vai\", \"x_range\": (814, 826), \"y_range\": (462, 475)},\n",
        "]\n",
        "\n",
        "def map_center_to_object(x, y):\n",
        "    \"\"\"\n",
        "    Maps the center coordinates (x, y) to an object name based on predefined ranges.\n",
        "    \"\"\"\n",
        "    for region in ranges:\n",
        "        if region[\"x_range\"][0] <= x <= region[\"x_range\"][1] and region[\"y_range\"][0] <= y <= region[\"y_range\"][1]:\n",
        "            return region[\"object\"]\n",
        "    return None\n",
        "\n",
        "# Step 4: Process video frames\n",
        "frame_skip = 2  # Process every 3rd frame\n",
        "frame_index = 0\n",
        "\n",
        "while cap.isOpened():\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    # Initialize object name to display\n",
        "    object_name = None\n",
        "\n",
        "    # Only process every 3rd frame\n",
        "    if frame_index % frame_skip == 0:\n",
        "        # Perform inference on the current frame\n",
        "        results = model.predict(frame, save=False, conf=0.5)\n",
        "\n",
        "        # Add bounding boxes and center points to the frame\n",
        "        for box in results[0].boxes.data.tolist():\n",
        "            # YOLO format: x_center y_center width height confidence class\n",
        "            x_center, y_center, width, height = box[0:4]\n",
        "\n",
        "            # Calculate absolute pixel positions\n",
        "            abs_x_center = int(x_center)\n",
        "            abs_y_center = int(y_center)\n",
        "            abs_width = int(width)\n",
        "            abs_height = int(height)\n",
        "\n",
        "            x1 = abs_x_center - (abs_width // 2)\n",
        "            y1 = abs_y_center - (abs_height // 2)\n",
        "            x2 = abs_x_center + (abs_width // 2)\n",
        "            y2 = abs_y_center + (abs_height // 2)\n",
        "\n",
        "            # Draw bounding box\n",
        "            # cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)  # Green bounding box\n",
        "\n",
        "            # Draw center position\n",
        "            cv2.circle(frame, (abs_x_center, abs_y_center), 10, (255, 0, 0), -1)  # Blue circle\n",
        "\n",
        "            # center_text = f\"({abs_x_center}, {abs_y_center})\"\n",
        "            # cv2.putText(frame, center_text, (abs_x_center + 10, abs_y_center - 10),\n",
        "            #             cv2.FONT_HERSHEY_SIMPLEX, 2.0, (0, 0, 255), 3)\n",
        "\n",
        "            # Map center to an object\n",
        "            object_name = map_center_to_object(abs_x_center, abs_y_center)\n",
        "\n",
        "    # Display the object name in the upper-right corner if found\n",
        "    if object_name:\n",
        "        cv2.putText(frame, object_name, (abs_x_center + 10, abs_y_center - 10), cv2.FONT_HERSHEY_SIMPLEX,\n",
        "                    2.0, (0, 0, 255), 3)  # Red color for object name\n",
        "\n",
        "    # Write the (processed or unprocessed) frame to the output video\n",
        "    out.write(frame)\n",
        "    frame_index += 1\n",
        "\n",
        "# Release resources\n",
        "cap.release()\n",
        "out.release()\n",
        "\n",
        "print(f\"Processed video saved to {output_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P2TiHgHG-AQ5",
        "outputId": "4ff5d0d8-d832-48a1-86d8-50d2d0dadc4f"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 448x768 (no detections), 11.6ms\n",
            "Speed: 3.0ms preprocess, 11.6ms inference, 0.6ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 7.2ms\n",
            "Speed: 2.9ms preprocess, 7.2ms inference, 0.6ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 7.0ms\n",
            "Speed: 4.5ms preprocess, 7.0ms inference, 0.6ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 7.5ms\n",
            "Speed: 3.9ms preprocess, 7.5ms inference, 0.6ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 7.7ms\n",
            "Speed: 4.5ms preprocess, 7.7ms inference, 0.6ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 7.3ms\n",
            "Speed: 4.2ms preprocess, 7.3ms inference, 0.6ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 7.3ms\n",
            "Speed: 3.0ms preprocess, 7.3ms inference, 0.6ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 7.4ms\n",
            "Speed: 4.6ms preprocess, 7.4ms inference, 0.6ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 14.2ms\n",
            "Speed: 4.1ms preprocess, 14.2ms inference, 0.8ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 7.2ms\n",
            "Speed: 4.1ms preprocess, 7.2ms inference, 0.6ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 7.4ms\n",
            "Speed: 2.9ms preprocess, 7.4ms inference, 0.6ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 7.5ms\n",
            "Speed: 4.8ms preprocess, 7.5ms inference, 0.6ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 7.5ms\n",
            "Speed: 2.9ms preprocess, 7.5ms inference, 0.6ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 14.1ms\n",
            "Speed: 4.1ms preprocess, 14.1ms inference, 1.0ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 11.8ms\n",
            "Speed: 4.2ms preprocess, 11.8ms inference, 0.9ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 13.5ms\n",
            "Speed: 5.1ms preprocess, 13.5ms inference, 0.8ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 10.5ms\n",
            "Speed: 5.1ms preprocess, 10.5ms inference, 0.7ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 10.4ms\n",
            "Speed: 3.9ms preprocess, 10.4ms inference, 0.8ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 7.2ms\n",
            "Speed: 4.0ms preprocess, 7.2ms inference, 0.6ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 7.4ms\n",
            "Speed: 3.7ms preprocess, 7.4ms inference, 0.6ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 7.1ms\n",
            "Speed: 3.4ms preprocess, 7.1ms inference, 0.6ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 7.5ms\n",
            "Speed: 3.3ms preprocess, 7.5ms inference, 0.6ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 7.4ms\n",
            "Speed: 4.0ms preprocess, 7.4ms inference, 0.8ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 7.8ms\n",
            "Speed: 3.7ms preprocess, 7.8ms inference, 0.6ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 7.4ms\n",
            "Speed: 3.9ms preprocess, 7.4ms inference, 0.6ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 7.0ms\n",
            "Speed: 3.7ms preprocess, 7.0ms inference, 0.6ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 10.7ms\n",
            "Speed: 4.3ms preprocess, 10.7ms inference, 0.9ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 12.5ms\n",
            "Speed: 5.0ms preprocess, 12.5ms inference, 0.8ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 12.8ms\n",
            "Speed: 4.1ms preprocess, 12.8ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 14.7ms\n",
            "Speed: 4.2ms preprocess, 14.7ms inference, 0.9ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 10.9ms\n",
            "Speed: 7.0ms preprocess, 10.9ms inference, 0.7ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 15.2ms\n",
            "Speed: 6.7ms preprocess, 15.2ms inference, 0.9ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 13.1ms\n",
            "Speed: 7.4ms preprocess, 13.1ms inference, 0.7ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 12.2ms\n",
            "Speed: 4.2ms preprocess, 12.2ms inference, 0.7ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 12.2ms\n",
            "Speed: 4.2ms preprocess, 12.2ms inference, 0.7ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 12.5ms\n",
            "Speed: 4.4ms preprocess, 12.5ms inference, 0.7ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 15.4ms\n",
            "Speed: 4.3ms preprocess, 15.4ms inference, 1.1ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 8.8ms\n",
            "Speed: 4.7ms preprocess, 8.8ms inference, 0.7ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 14.1ms\n",
            "Speed: 4.5ms preprocess, 14.1ms inference, 0.7ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 8.6ms\n",
            "Speed: 4.5ms preprocess, 8.6ms inference, 0.7ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 8.7ms\n",
            "Speed: 4.1ms preprocess, 8.7ms inference, 0.7ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 9.9ms\n",
            "Speed: 4.2ms preprocess, 9.9ms inference, 0.7ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 8.7ms\n",
            "Speed: 4.5ms preprocess, 8.7ms inference, 0.9ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 16.3ms\n",
            "Speed: 4.9ms preprocess, 16.3ms inference, 1.0ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 16.1ms\n",
            "Speed: 4.4ms preprocess, 16.1ms inference, 0.9ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 10.5ms\n",
            "Speed: 4.0ms preprocess, 10.5ms inference, 0.8ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 10.2ms\n",
            "Speed: 4.3ms preprocess, 10.2ms inference, 0.8ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 14.2ms\n",
            "Speed: 6.2ms preprocess, 14.2ms inference, 0.8ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 13.8ms\n",
            "Speed: 5.5ms preprocess, 13.8ms inference, 0.8ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 9.4ms\n",
            "Speed: 4.4ms preprocess, 9.4ms inference, 0.7ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 11.9ms\n",
            "Speed: 4.3ms preprocess, 11.9ms inference, 1.8ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 10.0ms\n",
            "Speed: 4.8ms preprocess, 10.0ms inference, 1.7ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 10.5ms\n",
            "Speed: 4.7ms preprocess, 10.5ms inference, 1.7ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 9.0ms\n",
            "Speed: 4.5ms preprocess, 9.0ms inference, 1.7ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 9.1ms\n",
            "Speed: 5.0ms preprocess, 9.1ms inference, 1.7ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 11.8ms\n",
            "Speed: 4.5ms preprocess, 11.8ms inference, 1.8ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 13.6ms\n",
            "Speed: 4.4ms preprocess, 13.6ms inference, 2.1ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 10.3ms\n",
            "Speed: 5.8ms preprocess, 10.3ms inference, 1.9ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 12.2ms\n",
            "Speed: 6.3ms preprocess, 12.2ms inference, 1.9ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 8.9ms\n",
            "Speed: 5.8ms preprocess, 8.9ms inference, 1.6ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 8.4ms\n",
            "Speed: 8.0ms preprocess, 8.4ms inference, 1.9ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 8.5ms\n",
            "Speed: 4.5ms preprocess, 8.5ms inference, 1.8ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 8.9ms\n",
            "Speed: 5.2ms preprocess, 8.9ms inference, 1.7ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 8.4ms\n",
            "Speed: 4.0ms preprocess, 8.4ms inference, 1.6ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 9.2ms\n",
            "Speed: 4.3ms preprocess, 9.2ms inference, 1.6ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 12.0ms\n",
            "Speed: 6.7ms preprocess, 12.0ms inference, 2.1ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 12.4ms\n",
            "Speed: 4.3ms preprocess, 12.4ms inference, 2.0ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 11.5ms\n",
            "Speed: 9.3ms preprocess, 11.5ms inference, 3.8ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 8.8ms\n",
            "Speed: 4.4ms preprocess, 8.8ms inference, 2.1ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 20.8ms\n",
            "Speed: 5.5ms preprocess, 20.8ms inference, 2.0ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 13.0ms\n",
            "Speed: 4.2ms preprocess, 13.0ms inference, 2.1ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 11.6ms\n",
            "Speed: 4.2ms preprocess, 11.6ms inference, 1.7ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 12.3ms\n",
            "Speed: 4.6ms preprocess, 12.3ms inference, 1.6ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 13.3ms\n",
            "Speed: 4.9ms preprocess, 13.3ms inference, 2.0ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 12.2ms\n",
            "Speed: 4.2ms preprocess, 12.2ms inference, 1.9ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 14.9ms\n",
            "Speed: 4.4ms preprocess, 14.9ms inference, 1.9ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 14.5ms\n",
            "Speed: 4.2ms preprocess, 14.5ms inference, 1.8ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 10.1ms\n",
            "Speed: 4.2ms preprocess, 10.1ms inference, 1.8ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 10.4ms\n",
            "Speed: 4.1ms preprocess, 10.4ms inference, 1.8ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 12.3ms\n",
            "Speed: 4.8ms preprocess, 12.3ms inference, 2.4ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 12.4ms\n",
            "Speed: 4.8ms preprocess, 12.4ms inference, 2.3ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 10.6ms\n",
            "Speed: 3.9ms preprocess, 10.6ms inference, 1.9ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 19.3ms\n",
            "Speed: 4.4ms preprocess, 19.3ms inference, 2.1ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 17.5ms\n",
            "Speed: 5.2ms preprocess, 17.5ms inference, 2.1ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 13.6ms\n",
            "Speed: 6.5ms preprocess, 13.6ms inference, 2.3ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 12.1ms\n",
            "Speed: 5.5ms preprocess, 12.1ms inference, 2.0ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 7.4ms\n",
            "Speed: 3.8ms preprocess, 7.4ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 7.0ms\n",
            "Speed: 3.1ms preprocess, 7.0ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 7.0ms\n",
            "Speed: 3.3ms preprocess, 7.0ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 7.0ms\n",
            "Speed: 3.7ms preprocess, 7.0ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 7.1ms\n",
            "Speed: 3.9ms preprocess, 7.1ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 7.1ms\n",
            "Speed: 3.3ms preprocess, 7.1ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 7.4ms\n",
            "Speed: 3.4ms preprocess, 7.4ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 7.1ms\n",
            "Speed: 4.1ms preprocess, 7.1ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 7.2ms\n",
            "Speed: 3.6ms preprocess, 7.2ms inference, 1.6ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 7.1ms\n",
            "Speed: 4.1ms preprocess, 7.1ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 7.0ms\n",
            "Speed: 3.1ms preprocess, 7.0ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 7.0ms\n",
            "Speed: 3.1ms preprocess, 7.0ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 7.1ms\n",
            "Speed: 3.6ms preprocess, 7.1ms inference, 1.5ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 12.8ms\n",
            "Speed: 4.0ms preprocess, 12.8ms inference, 1.8ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 15.7ms\n",
            "Speed: 6.7ms preprocess, 15.7ms inference, 1.1ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 10.8ms\n",
            "Speed: 5.2ms preprocess, 10.8ms inference, 0.9ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 10.4ms\n",
            "Speed: 4.7ms preprocess, 10.4ms inference, 0.8ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 9.4ms\n",
            "Speed: 5.0ms preprocess, 9.4ms inference, 0.7ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 7.3ms\n",
            "Speed: 3.8ms preprocess, 7.3ms inference, 0.6ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 7.0ms\n",
            "Speed: 3.3ms preprocess, 7.0ms inference, 0.6ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 7.2ms\n",
            "Speed: 3.5ms preprocess, 7.2ms inference, 0.6ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 7.2ms\n",
            "Speed: 4.1ms preprocess, 7.2ms inference, 0.6ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 7.3ms\n",
            "Speed: 3.7ms preprocess, 7.3ms inference, 0.6ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 7.4ms\n",
            "Speed: 3.6ms preprocess, 7.4ms inference, 0.6ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 7.7ms\n",
            "Speed: 4.4ms preprocess, 7.7ms inference, 0.6ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 7.5ms\n",
            "Speed: 4.5ms preprocess, 7.5ms inference, 0.7ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 7.1ms\n",
            "Speed: 4.1ms preprocess, 7.1ms inference, 0.6ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 7.5ms\n",
            "Speed: 3.7ms preprocess, 7.5ms inference, 0.6ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 7.2ms\n",
            "Speed: 3.0ms preprocess, 7.2ms inference, 0.6ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 7.0ms\n",
            "Speed: 3.1ms preprocess, 7.0ms inference, 0.6ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 7.0ms\n",
            "Speed: 2.9ms preprocess, 7.0ms inference, 0.6ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 7.3ms\n",
            "Speed: 4.1ms preprocess, 7.3ms inference, 0.6ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 10.9ms\n",
            "Speed: 4.3ms preprocess, 10.9ms inference, 0.7ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 10.9ms\n",
            "Speed: 4.0ms preprocess, 10.9ms inference, 0.8ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 2 Hand_Raiseds, 11.4ms\n",
            "Speed: 4.2ms preprocess, 11.4ms inference, 1.7ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 10.1ms\n",
            "Speed: 4.0ms preprocess, 10.1ms inference, 1.5ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 11.3ms\n",
            "Speed: 4.1ms preprocess, 11.3ms inference, 1.9ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 7.0ms\n",
            "Speed: 4.3ms preprocess, 7.0ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 7.0ms\n",
            "Speed: 3.2ms preprocess, 7.0ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 7.5ms\n",
            "Speed: 2.8ms preprocess, 7.5ms inference, 1.5ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 7.2ms\n",
            "Speed: 5.2ms preprocess, 7.2ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 8.0ms\n",
            "Speed: 4.3ms preprocess, 8.0ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 8.3ms\n",
            "Speed: 4.5ms preprocess, 8.3ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 7.2ms\n",
            "Speed: 4.9ms preprocess, 7.2ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 7.4ms\n",
            "Speed: 4.9ms preprocess, 7.4ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 7.4ms\n",
            "Speed: 3.0ms preprocess, 7.4ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 7.8ms\n",
            "Speed: 3.3ms preprocess, 7.8ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 7.7ms\n",
            "Speed: 3.6ms preprocess, 7.7ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 7.2ms\n",
            "Speed: 3.4ms preprocess, 7.2ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 7.6ms\n",
            "Speed: 3.5ms preprocess, 7.6ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 7.5ms\n",
            "Speed: 3.2ms preprocess, 7.5ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 10.1ms\n",
            "Speed: 5.7ms preprocess, 10.1ms inference, 1.7ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 10.8ms\n",
            "Speed: 4.4ms preprocess, 10.8ms inference, 1.9ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 10.1ms\n",
            "Speed: 4.1ms preprocess, 10.1ms inference, 1.9ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 10.9ms\n",
            "Speed: 7.0ms preprocess, 10.9ms inference, 2.0ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 7.2ms\n",
            "Speed: 4.2ms preprocess, 7.2ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 7.0ms\n",
            "Speed: 3.9ms preprocess, 7.0ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 7.5ms\n",
            "Speed: 4.4ms preprocess, 7.5ms inference, 1.5ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 7.7ms\n",
            "Speed: 4.0ms preprocess, 7.7ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 7.0ms\n",
            "Speed: 3.3ms preprocess, 7.0ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 7.5ms\n",
            "Speed: 3.2ms preprocess, 7.5ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 7.4ms\n",
            "Speed: 3.2ms preprocess, 7.4ms inference, 1.5ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 7.8ms\n",
            "Speed: 2.9ms preprocess, 7.8ms inference, 1.5ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 7.6ms\n",
            "Speed: 4.6ms preprocess, 7.6ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 7.0ms\n",
            "Speed: 3.8ms preprocess, 7.0ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 7.3ms\n",
            "Speed: 4.0ms preprocess, 7.3ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 7.3ms\n",
            "Speed: 4.2ms preprocess, 7.3ms inference, 0.6ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 7.1ms\n",
            "Speed: 4.0ms preprocess, 7.1ms inference, 0.6ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 8.6ms\n",
            "Speed: 4.2ms preprocess, 8.6ms inference, 0.6ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 10.2ms\n",
            "Speed: 4.5ms preprocess, 10.2ms inference, 0.7ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 11.0ms\n",
            "Speed: 3.6ms preprocess, 11.0ms inference, 0.7ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 10.8ms\n",
            "Speed: 3.9ms preprocess, 10.8ms inference, 0.9ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 14.8ms\n",
            "Speed: 6.5ms preprocess, 14.8ms inference, 0.9ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 10.2ms\n",
            "Speed: 4.6ms preprocess, 10.2ms inference, 0.7ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 7.0ms\n",
            "Speed: 2.9ms preprocess, 7.0ms inference, 0.6ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 7.1ms\n",
            "Speed: 3.1ms preprocess, 7.1ms inference, 0.6ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 7.5ms\n",
            "Speed: 4.0ms preprocess, 7.5ms inference, 0.6ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 7.8ms\n",
            "Speed: 4.1ms preprocess, 7.8ms inference, 0.6ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 7.0ms\n",
            "Speed: 4.0ms preprocess, 7.0ms inference, 0.6ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 7.2ms\n",
            "Speed: 4.1ms preprocess, 7.2ms inference, 0.6ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 7.0ms\n",
            "Speed: 4.3ms preprocess, 7.0ms inference, 0.6ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 7.0ms\n",
            "Speed: 3.3ms preprocess, 7.0ms inference, 1.6ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 7.4ms\n",
            "Speed: 4.0ms preprocess, 7.4ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 7.0ms\n",
            "Speed: 3.3ms preprocess, 7.0ms inference, 1.6ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 7.4ms\n",
            "Speed: 2.8ms preprocess, 7.4ms inference, 1.5ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 7.4ms\n",
            "Speed: 3.1ms preprocess, 7.4ms inference, 1.5ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 7.2ms\n",
            "Speed: 2.8ms preprocess, 7.2ms inference, 1.5ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 7.0ms\n",
            "Speed: 3.7ms preprocess, 7.0ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 15.6ms\n",
            "Speed: 4.5ms preprocess, 15.6ms inference, 1.7ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 10.0ms\n",
            "Speed: 6.5ms preprocess, 10.0ms inference, 1.7ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 15.7ms\n",
            "Speed: 6.8ms preprocess, 15.7ms inference, 2.1ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 9.9ms\n",
            "Speed: 4.8ms preprocess, 9.9ms inference, 2.2ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 9.9ms\n",
            "Speed: 4.4ms preprocess, 9.9ms inference, 1.8ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 7.3ms\n",
            "Speed: 4.2ms preprocess, 7.3ms inference, 2.0ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 7.5ms\n",
            "Speed: 4.2ms preprocess, 7.5ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 7.8ms\n",
            "Speed: 5.7ms preprocess, 7.8ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 7.2ms\n",
            "Speed: 4.1ms preprocess, 7.2ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 7.9ms\n",
            "Speed: 4.0ms preprocess, 7.9ms inference, 1.5ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 7.9ms\n",
            "Speed: 5.6ms preprocess, 7.9ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 8.6ms\n",
            "Speed: 4.1ms preprocess, 8.6ms inference, 1.6ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 9.3ms\n",
            "Speed: 6.3ms preprocess, 9.3ms inference, 1.5ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 7.0ms\n",
            "Speed: 4.2ms preprocess, 7.0ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 7.0ms\n",
            "Speed: 3.5ms preprocess, 7.0ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 7.0ms\n",
            "Speed: 2.9ms preprocess, 7.0ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 7.5ms\n",
            "Speed: 4.9ms preprocess, 7.5ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 11.3ms\n",
            "Speed: 5.0ms preprocess, 11.3ms inference, 1.8ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 10.0ms\n",
            "Speed: 4.9ms preprocess, 10.0ms inference, 1.9ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 9.9ms\n",
            "Speed: 3.7ms preprocess, 9.9ms inference, 1.6ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 7.4ms\n",
            "Speed: 5.1ms preprocess, 7.4ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 12.3ms\n",
            "Speed: 5.9ms preprocess, 12.3ms inference, 2.3ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 7.1ms\n",
            "Speed: 4.0ms preprocess, 7.1ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 7.4ms\n",
            "Speed: 3.1ms preprocess, 7.4ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 7.3ms\n",
            "Speed: 3.5ms preprocess, 7.3ms inference, 1.8ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 13.8ms\n",
            "Speed: 3.0ms preprocess, 13.8ms inference, 1.5ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 2 Hand_Raiseds, 7.3ms\n",
            "Speed: 4.7ms preprocess, 7.3ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 7.6ms\n",
            "Speed: 3.6ms preprocess, 7.6ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 7.2ms\n",
            "Speed: 4.7ms preprocess, 7.2ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 7.7ms\n",
            "Speed: 2.9ms preprocess, 7.7ms inference, 1.6ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 7.8ms\n",
            "Speed: 5.5ms preprocess, 7.8ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 8.8ms\n",
            "Speed: 6.0ms preprocess, 8.8ms inference, 1.5ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 7.2ms\n",
            "Speed: 4.6ms preprocess, 7.2ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 7.3ms\n",
            "Speed: 3.8ms preprocess, 7.3ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 7.4ms\n",
            "Speed: 3.6ms preprocess, 7.4ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 9.8ms\n",
            "Speed: 4.0ms preprocess, 9.8ms inference, 1.7ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 10.8ms\n",
            "Speed: 3.8ms preprocess, 10.8ms inference, 1.8ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 10.3ms\n",
            "Speed: 3.7ms preprocess, 10.3ms inference, 1.8ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 12.1ms\n",
            "Speed: 4.2ms preprocess, 12.1ms inference, 2.2ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 10.0ms\n",
            "Speed: 4.3ms preprocess, 10.0ms inference, 1.8ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 14.4ms\n",
            "Speed: 4.9ms preprocess, 14.4ms inference, 1.9ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 2 Hand_Raiseds, 7.4ms\n",
            "Speed: 3.8ms preprocess, 7.4ms inference, 1.5ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 2 Hand_Raiseds, 7.2ms\n",
            "Speed: 3.1ms preprocess, 7.2ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 2 Hand_Raiseds, 7.2ms\n",
            "Speed: 3.5ms preprocess, 7.2ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 7.4ms\n",
            "Speed: 3.3ms preprocess, 7.4ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 8.0ms\n",
            "Speed: 4.1ms preprocess, 8.0ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 7.6ms\n",
            "Speed: 5.1ms preprocess, 7.6ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 8.0ms\n",
            "Speed: 4.2ms preprocess, 8.0ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 8.6ms\n",
            "Speed: 4.9ms preprocess, 8.6ms inference, 1.5ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 7.5ms\n",
            "Speed: 4.3ms preprocess, 7.5ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 7.0ms\n",
            "Speed: 3.9ms preprocess, 7.0ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 7.3ms\n",
            "Speed: 4.9ms preprocess, 7.3ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 7.3ms\n",
            "Speed: 4.7ms preprocess, 7.3ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 10.1ms\n",
            "Speed: 5.5ms preprocess, 10.1ms inference, 2.0ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 9.8ms\n",
            "Speed: 3.9ms preprocess, 9.8ms inference, 1.7ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 10.3ms\n",
            "Speed: 5.3ms preprocess, 10.3ms inference, 2.0ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 10.3ms\n",
            "Speed: 4.8ms preprocess, 10.3ms inference, 2.0ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 8.7ms\n",
            "Speed: 7.7ms preprocess, 8.7ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 7.0ms\n",
            "Speed: 3.6ms preprocess, 7.0ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 7.8ms\n",
            "Speed: 4.2ms preprocess, 7.8ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 7.2ms\n",
            "Speed: 3.4ms preprocess, 7.2ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 7.0ms\n",
            "Speed: 2.9ms preprocess, 7.0ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 7.5ms\n",
            "Speed: 4.1ms preprocess, 7.5ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 8.4ms\n",
            "Speed: 4.0ms preprocess, 8.4ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 7.4ms\n",
            "Speed: 3.0ms preprocess, 7.4ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 7.7ms\n",
            "Speed: 4.4ms preprocess, 7.7ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 8.4ms\n",
            "Speed: 5.3ms preprocess, 8.4ms inference, 1.5ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 7.9ms\n",
            "Speed: 3.4ms preprocess, 7.9ms inference, 1.5ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 8.2ms\n",
            "Speed: 3.4ms preprocess, 8.2ms inference, 1.5ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 7.6ms\n",
            "Speed: 4.8ms preprocess, 7.6ms inference, 1.5ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 7.1ms\n",
            "Speed: 4.4ms preprocess, 7.1ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 9.9ms\n",
            "Speed: 4.7ms preprocess, 9.9ms inference, 1.8ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 9.3ms\n",
            "Speed: 3.9ms preprocess, 9.3ms inference, 1.7ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 10.0ms\n",
            "Speed: 3.9ms preprocess, 10.0ms inference, 0.7ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 11.7ms\n",
            "Speed: 8.3ms preprocess, 11.7ms inference, 0.8ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 9.4ms\n",
            "Speed: 6.1ms preprocess, 9.4ms inference, 0.6ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 7.0ms\n",
            "Speed: 2.9ms preprocess, 7.0ms inference, 0.6ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 13.9ms\n",
            "Speed: 6.2ms preprocess, 13.9ms inference, 0.9ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 7.4ms\n",
            "Speed: 3.0ms preprocess, 7.4ms inference, 0.7ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 7.0ms\n",
            "Speed: 3.1ms preprocess, 7.0ms inference, 0.6ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 7.1ms\n",
            "Speed: 3.5ms preprocess, 7.1ms inference, 0.6ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 7.4ms\n",
            "Speed: 4.4ms preprocess, 7.4ms inference, 0.7ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 9.8ms\n",
            "Speed: 4.2ms preprocess, 9.8ms inference, 0.7ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 8.5ms\n",
            "Speed: 4.1ms preprocess, 8.5ms inference, 0.6ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 7.2ms\n",
            "Speed: 3.7ms preprocess, 7.2ms inference, 0.6ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 8.2ms\n",
            "Speed: 4.0ms preprocess, 8.2ms inference, 0.6ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 7.2ms\n",
            "Speed: 3.0ms preprocess, 7.2ms inference, 0.7ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 9.7ms\n",
            "Speed: 5.2ms preprocess, 9.7ms inference, 0.6ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 7.4ms\n",
            "Speed: 4.0ms preprocess, 7.4ms inference, 0.6ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 7.1ms\n",
            "Speed: 3.3ms preprocess, 7.1ms inference, 0.6ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 13.3ms\n",
            "Speed: 6.7ms preprocess, 13.3ms inference, 1.5ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 15.1ms\n",
            "Speed: 5.5ms preprocess, 15.1ms inference, 0.9ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 10.8ms\n",
            "Speed: 7.4ms preprocess, 10.8ms inference, 0.8ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 10.3ms\n",
            "Speed: 5.0ms preprocess, 10.3ms inference, 0.7ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 8.6ms\n",
            "Speed: 4.8ms preprocess, 8.6ms inference, 0.6ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 11.0ms\n",
            "Speed: 4.3ms preprocess, 11.0ms inference, 0.9ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 11.2ms\n",
            "Speed: 4.4ms preprocess, 11.2ms inference, 0.9ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 11.1ms\n",
            "Speed: 6.8ms preprocess, 11.1ms inference, 0.7ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 15.2ms\n",
            "Speed: 4.6ms preprocess, 15.2ms inference, 0.8ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 13.1ms\n",
            "Speed: 6.8ms preprocess, 13.1ms inference, 0.8ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 10.9ms\n",
            "Speed: 4.4ms preprocess, 10.9ms inference, 0.7ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 8.9ms\n",
            "Speed: 5.6ms preprocess, 8.9ms inference, 0.7ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 10.0ms\n",
            "Speed: 4.4ms preprocess, 10.0ms inference, 0.8ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 9.2ms\n",
            "Speed: 4.4ms preprocess, 9.2ms inference, 0.8ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 11.2ms\n",
            "Speed: 5.1ms preprocess, 11.2ms inference, 0.8ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 14.7ms\n",
            "Speed: 5.7ms preprocess, 14.7ms inference, 1.1ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 15.9ms\n",
            "Speed: 4.5ms preprocess, 15.9ms inference, 0.7ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 11.9ms\n",
            "Speed: 4.5ms preprocess, 11.9ms inference, 0.7ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 9.8ms\n",
            "Speed: 4.5ms preprocess, 9.8ms inference, 0.7ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 13.3ms\n",
            "Speed: 5.1ms preprocess, 13.3ms inference, 0.8ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 8.6ms\n",
            "Speed: 7.4ms preprocess, 8.6ms inference, 0.7ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 9.8ms\n",
            "Speed: 4.3ms preprocess, 9.8ms inference, 0.7ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 10.9ms\n",
            "Speed: 4.3ms preprocess, 10.9ms inference, 0.8ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 13.2ms\n",
            "Speed: 4.4ms preprocess, 13.2ms inference, 0.9ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 9.6ms\n",
            "Speed: 4.4ms preprocess, 9.6ms inference, 0.7ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 11.8ms\n",
            "Speed: 5.2ms preprocess, 11.8ms inference, 0.8ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 10.2ms\n",
            "Speed: 4.4ms preprocess, 10.2ms inference, 0.7ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 14.4ms\n",
            "Speed: 6.4ms preprocess, 14.4ms inference, 1.0ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 11.8ms\n",
            "Speed: 8.0ms preprocess, 11.8ms inference, 1.5ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 15.6ms\n",
            "Speed: 4.5ms preprocess, 15.6ms inference, 0.8ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 11.9ms\n",
            "Speed: 6.6ms preprocess, 11.9ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 8.7ms\n",
            "Speed: 4.2ms preprocess, 8.7ms inference, 1.7ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 9.2ms\n",
            "Speed: 4.8ms preprocess, 9.2ms inference, 1.7ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 12.5ms\n",
            "Speed: 4.2ms preprocess, 12.5ms inference, 2.4ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 9.7ms\n",
            "Speed: 5.0ms preprocess, 9.7ms inference, 1.8ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 13.6ms\n",
            "Speed: 4.3ms preprocess, 13.6ms inference, 1.8ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 9.3ms\n",
            "Speed: 4.4ms preprocess, 9.3ms inference, 1.7ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 9.8ms\n",
            "Speed: 4.4ms preprocess, 9.8ms inference, 1.6ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 8.5ms\n",
            "Speed: 4.2ms preprocess, 8.5ms inference, 1.7ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 11.3ms\n",
            "Speed: 4.3ms preprocess, 11.3ms inference, 1.7ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 15.9ms\n",
            "Speed: 6.1ms preprocess, 15.9ms inference, 3.4ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 9.3ms\n",
            "Speed: 4.4ms preprocess, 9.3ms inference, 1.6ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 9.6ms\n",
            "Speed: 4.5ms preprocess, 9.6ms inference, 1.7ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 11.8ms\n",
            "Speed: 6.4ms preprocess, 11.8ms inference, 2.0ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 12.3ms\n",
            "Speed: 5.1ms preprocess, 12.3ms inference, 3.9ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 12.6ms\n",
            "Speed: 6.7ms preprocess, 12.6ms inference, 2.0ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 10.4ms\n",
            "Speed: 4.1ms preprocess, 10.4ms inference, 1.8ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 15.7ms\n",
            "Speed: 4.3ms preprocess, 15.7ms inference, 1.7ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 12.0ms\n",
            "Speed: 6.5ms preprocess, 12.0ms inference, 2.0ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 14.5ms\n",
            "Speed: 4.4ms preprocess, 14.5ms inference, 1.9ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 11.7ms\n",
            "Speed: 5.2ms preprocess, 11.7ms inference, 2.1ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 12.9ms\n",
            "Speed: 4.2ms preprocess, 12.9ms inference, 2.2ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 12.3ms\n",
            "Speed: 4.5ms preprocess, 12.3ms inference, 2.0ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 16.9ms\n",
            "Speed: 4.2ms preprocess, 16.9ms inference, 2.8ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 13.2ms\n",
            "Speed: 5.3ms preprocess, 13.2ms inference, 2.3ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 11.1ms\n",
            "Speed: 4.1ms preprocess, 11.1ms inference, 1.9ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 10.4ms\n",
            "Speed: 4.4ms preprocess, 10.4ms inference, 1.9ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 12.0ms\n",
            "Speed: 4.4ms preprocess, 12.0ms inference, 1.9ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 11.7ms\n",
            "Speed: 5.1ms preprocess, 11.7ms inference, 2.0ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 13.3ms\n",
            "Speed: 5.3ms preprocess, 13.3ms inference, 2.1ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 12.2ms\n",
            "Speed: 5.6ms preprocess, 12.2ms inference, 2.1ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 12.7ms\n",
            "Speed: 5.8ms preprocess, 12.7ms inference, 2.0ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 12.3ms\n",
            "Speed: 5.9ms preprocess, 12.3ms inference, 2.2ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 7.5ms\n",
            "Speed: 4.2ms preprocess, 7.5ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 7.2ms\n",
            "Speed: 4.1ms preprocess, 7.2ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 15.8ms\n",
            "Speed: 4.5ms preprocess, 15.8ms inference, 1.8ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 9.6ms\n",
            "Speed: 3.4ms preprocess, 9.6ms inference, 1.7ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 12.4ms\n",
            "Speed: 4.5ms preprocess, 12.4ms inference, 1.8ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 7.0ms\n",
            "Speed: 4.2ms preprocess, 7.0ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 11.7ms\n",
            "Speed: 5.4ms preprocess, 11.7ms inference, 1.9ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 7.0ms\n",
            "Speed: 3.1ms preprocess, 7.0ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 7.4ms\n",
            "Speed: 4.1ms preprocess, 7.4ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 7.3ms\n",
            "Speed: 4.5ms preprocess, 7.3ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 7.2ms\n",
            "Speed: 3.1ms preprocess, 7.2ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 7.2ms\n",
            "Speed: 3.8ms preprocess, 7.2ms inference, 1.5ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 7.4ms\n",
            "Speed: 3.6ms preprocess, 7.4ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 7.3ms\n",
            "Speed: 3.3ms preprocess, 7.3ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 16.0ms\n",
            "Speed: 4.3ms preprocess, 16.0ms inference, 1.5ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 7.5ms\n",
            "Speed: 4.0ms preprocess, 7.5ms inference, 1.6ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 7.3ms\n",
            "Speed: 3.6ms preprocess, 7.3ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 12.9ms\n",
            "Speed: 4.8ms preprocess, 12.9ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 8.2ms\n",
            "Speed: 4.9ms preprocess, 8.2ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 10.5ms\n",
            "Speed: 3.1ms preprocess, 10.5ms inference, 0.8ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 13.1ms\n",
            "Speed: 5.9ms preprocess, 13.1ms inference, 1.0ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 11.3ms\n",
            "Speed: 4.0ms preprocess, 11.3ms inference, 0.7ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 11.1ms\n",
            "Speed: 5.4ms preprocess, 11.1ms inference, 0.7ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 10.5ms\n",
            "Speed: 5.1ms preprocess, 10.5ms inference, 0.7ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 7.8ms\n",
            "Speed: 4.7ms preprocess, 7.8ms inference, 0.9ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 7.4ms\n",
            "Speed: 3.4ms preprocess, 7.4ms inference, 0.6ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 7.8ms\n",
            "Speed: 4.8ms preprocess, 7.8ms inference, 0.6ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 8.6ms\n",
            "Speed: 4.6ms preprocess, 8.6ms inference, 0.6ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 8.1ms\n",
            "Speed: 4.3ms preprocess, 8.1ms inference, 0.6ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 7.2ms\n",
            "Speed: 3.2ms preprocess, 7.2ms inference, 0.6ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 8.6ms\n",
            "Speed: 4.5ms preprocess, 8.6ms inference, 0.7ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 7.3ms\n",
            "Speed: 5.7ms preprocess, 7.3ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 15.5ms\n",
            "Speed: 3.7ms preprocess, 15.5ms inference, 2.1ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 7.7ms\n",
            "Speed: 4.2ms preprocess, 7.7ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 8.3ms\n",
            "Speed: 5.7ms preprocess, 8.3ms inference, 1.6ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 10.0ms\n",
            "Speed: 3.7ms preprocess, 10.0ms inference, 1.5ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 7.2ms\n",
            "Speed: 4.0ms preprocess, 7.2ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 9.9ms\n",
            "Speed: 5.0ms preprocess, 9.9ms inference, 1.7ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 9.7ms\n",
            "Speed: 4.2ms preprocess, 9.7ms inference, 1.7ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 10.0ms\n",
            "Speed: 4.3ms preprocess, 10.0ms inference, 1.9ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 10.1ms\n",
            "Speed: 4.8ms preprocess, 10.1ms inference, 1.7ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 9.7ms\n",
            "Speed: 4.1ms preprocess, 9.7ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 7.9ms\n",
            "Speed: 7.4ms preprocess, 7.9ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 7.1ms\n",
            "Speed: 3.5ms preprocess, 7.1ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 9.2ms\n",
            "Speed: 4.1ms preprocess, 9.2ms inference, 1.5ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 7.6ms\n",
            "Speed: 3.6ms preprocess, 7.6ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 7.1ms\n",
            "Speed: 4.4ms preprocess, 7.1ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 7.2ms\n",
            "Speed: 3.5ms preprocess, 7.2ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 7.4ms\n",
            "Speed: 3.8ms preprocess, 7.4ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 7.1ms\n",
            "Speed: 3.0ms preprocess, 7.1ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 10.8ms\n",
            "Speed: 3.7ms preprocess, 10.8ms inference, 2.0ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 7.1ms\n",
            "Speed: 3.7ms preprocess, 7.1ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 7.2ms\n",
            "Speed: 4.1ms preprocess, 7.2ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 7.1ms\n",
            "Speed: 4.1ms preprocess, 7.1ms inference, 0.6ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 7.7ms\n",
            "Speed: 4.1ms preprocess, 7.7ms inference, 0.6ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 10.1ms\n",
            "Speed: 3.9ms preprocess, 10.1ms inference, 0.7ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 10.3ms\n",
            "Speed: 4.2ms preprocess, 10.3ms inference, 0.7ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 11.1ms\n",
            "Speed: 4.7ms preprocess, 11.1ms inference, 0.8ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 10.3ms\n",
            "Speed: 3.9ms preprocess, 10.3ms inference, 0.7ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 8.6ms\n",
            "Speed: 3.9ms preprocess, 8.6ms inference, 0.6ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 7.3ms\n",
            "Speed: 4.5ms preprocess, 7.3ms inference, 0.6ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 7.0ms\n",
            "Speed: 4.1ms preprocess, 7.0ms inference, 0.6ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 7.5ms\n",
            "Speed: 4.3ms preprocess, 7.5ms inference, 0.6ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 7.3ms\n",
            "Speed: 4.5ms preprocess, 7.3ms inference, 0.6ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 9.0ms\n",
            "Speed: 4.7ms preprocess, 9.0ms inference, 0.6ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 7.7ms\n",
            "Speed: 4.1ms preprocess, 7.7ms inference, 0.7ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 7.0ms\n",
            "Speed: 3.7ms preprocess, 7.0ms inference, 0.6ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 7.2ms\n",
            "Speed: 3.3ms preprocess, 7.2ms inference, 0.6ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 7.6ms\n",
            "Speed: 4.8ms preprocess, 7.6ms inference, 0.7ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 8.6ms\n",
            "Speed: 4.2ms preprocess, 8.6ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 11.3ms\n",
            "Speed: 4.6ms preprocess, 11.3ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 7.8ms\n",
            "Speed: 4.1ms preprocess, 7.8ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 7.3ms\n",
            "Speed: 5.9ms preprocess, 7.3ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 7.0ms\n",
            "Speed: 3.6ms preprocess, 7.0ms inference, 1.6ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 10.5ms\n",
            "Speed: 4.3ms preprocess, 10.5ms inference, 1.7ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 10.3ms\n",
            "Speed: 4.6ms preprocess, 10.3ms inference, 1.8ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 10.2ms\n",
            "Speed: 4.5ms preprocess, 10.2ms inference, 1.6ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 9.8ms\n",
            "Speed: 3.4ms preprocess, 9.8ms inference, 1.7ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 7.0ms\n",
            "Speed: 3.6ms preprocess, 7.0ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 7.8ms\n",
            "Speed: 4.1ms preprocess, 7.8ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 10.1ms\n",
            "Speed: 4.1ms preprocess, 10.1ms inference, 1.5ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 7.8ms\n",
            "Speed: 3.3ms preprocess, 7.8ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 8.5ms\n",
            "Speed: 4.2ms preprocess, 8.5ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 7.7ms\n",
            "Speed: 4.1ms preprocess, 7.7ms inference, 1.6ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 7.5ms\n",
            "Speed: 3.8ms preprocess, 7.5ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 7.7ms\n",
            "Speed: 4.5ms preprocess, 7.7ms inference, 1.5ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 7.9ms\n",
            "Speed: 4.1ms preprocess, 7.9ms inference, 1.5ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 7.4ms\n",
            "Speed: 3.3ms preprocess, 7.4ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 15.1ms\n",
            "Speed: 4.7ms preprocess, 15.1ms inference, 1.5ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 7.3ms\n",
            "Speed: 3.7ms preprocess, 7.3ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 8.5ms\n",
            "Speed: 4.4ms preprocess, 8.5ms inference, 1.5ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 10.9ms\n",
            "Speed: 3.8ms preprocess, 10.9ms inference, 1.9ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 10.0ms\n",
            "Speed: 4.0ms preprocess, 10.0ms inference, 1.8ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 10.0ms\n",
            "Speed: 4.0ms preprocess, 10.0ms inference, 2.2ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 9.7ms\n",
            "Speed: 6.3ms preprocess, 9.7ms inference, 1.9ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 9.2ms\n",
            "Speed: 4.6ms preprocess, 9.2ms inference, 1.7ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 7.1ms\n",
            "Speed: 3.7ms preprocess, 7.1ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 7.1ms\n",
            "Speed: 6.0ms preprocess, 7.1ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 7.0ms\n",
            "Speed: 5.1ms preprocess, 7.0ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 7.5ms\n",
            "Speed: 4.2ms preprocess, 7.5ms inference, 1.5ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 7.3ms\n",
            "Speed: 4.2ms preprocess, 7.3ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 8.0ms\n",
            "Speed: 3.5ms preprocess, 8.0ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 7.1ms\n",
            "Speed: 4.1ms preprocess, 7.1ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 7.3ms\n",
            "Speed: 3.8ms preprocess, 7.3ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 8.4ms\n",
            "Speed: 4.1ms preprocess, 8.4ms inference, 0.6ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 11.2ms\n",
            "Speed: 4.3ms preprocess, 11.2ms inference, 0.7ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 9.5ms\n",
            "Speed: 4.2ms preprocess, 9.5ms inference, 0.9ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 13.2ms\n",
            "Speed: 4.4ms preprocess, 13.2ms inference, 0.6ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 7.6ms\n",
            "Speed: 4.3ms preprocess, 7.6ms inference, 0.6ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 15.4ms\n",
            "Speed: 6.5ms preprocess, 15.4ms inference, 0.7ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 10.6ms\n",
            "Speed: 4.9ms preprocess, 10.6ms inference, 0.6ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 12.1ms\n",
            "Speed: 4.4ms preprocess, 12.1ms inference, 0.8ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 10.2ms\n",
            "Speed: 6.0ms preprocess, 10.2ms inference, 0.8ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 13.0ms\n",
            "Speed: 4.4ms preprocess, 13.0ms inference, 0.7ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 7.8ms\n",
            "Speed: 4.8ms preprocess, 7.8ms inference, 0.6ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 7.1ms\n",
            "Speed: 4.0ms preprocess, 7.1ms inference, 0.6ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 7.3ms\n",
            "Speed: 4.4ms preprocess, 7.3ms inference, 0.6ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 7.5ms\n",
            "Speed: 4.1ms preprocess, 7.5ms inference, 0.6ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 8.7ms\n",
            "Speed: 4.0ms preprocess, 8.7ms inference, 0.6ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 7.7ms\n",
            "Speed: 4.3ms preprocess, 7.7ms inference, 0.8ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 7.4ms\n",
            "Speed: 4.9ms preprocess, 7.4ms inference, 0.6ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 7.0ms\n",
            "Speed: 2.9ms preprocess, 7.0ms inference, 0.6ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 7.7ms\n",
            "Speed: 5.3ms preprocess, 7.7ms inference, 0.6ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 7.6ms\n",
            "Speed: 3.4ms preprocess, 7.6ms inference, 0.6ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 7.1ms\n",
            "Speed: 2.8ms preprocess, 7.1ms inference, 0.6ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 7.1ms\n",
            "Speed: 3.0ms preprocess, 7.1ms inference, 0.6ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 12.0ms\n",
            "Speed: 5.4ms preprocess, 12.0ms inference, 0.9ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 7.2ms\n",
            "Speed: 4.5ms preprocess, 7.2ms inference, 0.6ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 33.5ms\n",
            "Speed: 13.6ms preprocess, 33.5ms inference, 2.0ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 7.2ms\n",
            "Speed: 3.0ms preprocess, 7.2ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 7.4ms\n",
            "Speed: 4.3ms preprocess, 7.4ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 7.3ms\n",
            "Speed: 4.3ms preprocess, 7.3ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 7.1ms\n",
            "Speed: 3.6ms preprocess, 7.1ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 7.7ms\n",
            "Speed: 2.9ms preprocess, 7.7ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 9.9ms\n",
            "Speed: 6.1ms preprocess, 9.9ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 2 Hand_Raiseds, 7.6ms\n",
            "Speed: 3.8ms preprocess, 7.6ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 7.2ms\n",
            "Speed: 5.8ms preprocess, 7.2ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 7.1ms\n",
            "Speed: 4.9ms preprocess, 7.1ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 7.4ms\n",
            "Speed: 4.4ms preprocess, 7.4ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 7.6ms\n",
            "Speed: 4.7ms preprocess, 7.6ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 7.1ms\n",
            "Speed: 4.5ms preprocess, 7.1ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 8.5ms\n",
            "Speed: 2.9ms preprocess, 8.5ms inference, 1.9ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 7.3ms\n",
            "Speed: 3.8ms preprocess, 7.3ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 11.8ms\n",
            "Speed: 4.9ms preprocess, 11.8ms inference, 2.2ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 9.8ms\n",
            "Speed: 3.5ms preprocess, 9.8ms inference, 1.8ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 10.2ms\n",
            "Speed: 6.1ms preprocess, 10.2ms inference, 1.7ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 11.8ms\n",
            "Speed: 4.9ms preprocess, 11.8ms inference, 1.8ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 10.7ms\n",
            "Speed: 5.0ms preprocess, 10.7ms inference, 1.9ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 10.4ms\n",
            "Speed: 5.7ms preprocess, 10.4ms inference, 1.8ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 7.1ms\n",
            "Speed: 4.7ms preprocess, 7.1ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 7.1ms\n",
            "Speed: 4.9ms preprocess, 7.1ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 7.9ms\n",
            "Speed: 4.8ms preprocess, 7.9ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 10.2ms\n",
            "Speed: 4.1ms preprocess, 10.2ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 7.6ms\n",
            "Speed: 4.3ms preprocess, 7.6ms inference, 1.6ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 7.1ms\n",
            "Speed: 4.7ms preprocess, 7.1ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 10.4ms\n",
            "Speed: 5.3ms preprocess, 10.4ms inference, 1.9ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 7.2ms\n",
            "Speed: 5.2ms preprocess, 7.2ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 7.1ms\n",
            "Speed: 4.8ms preprocess, 7.1ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 7.5ms\n",
            "Speed: 4.6ms preprocess, 7.5ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 9.1ms\n",
            "Speed: 4.8ms preprocess, 9.1ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 7.6ms\n",
            "Speed: 4.4ms preprocess, 7.6ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 8.7ms\n",
            "Speed: 4.1ms preprocess, 8.7ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 10.4ms\n",
            "Speed: 4.4ms preprocess, 10.4ms inference, 1.7ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 11.4ms\n",
            "Speed: 5.2ms preprocess, 11.4ms inference, 1.9ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 10.0ms\n",
            "Speed: 4.0ms preprocess, 10.0ms inference, 1.7ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 9.8ms\n",
            "Speed: 6.0ms preprocess, 9.8ms inference, 1.7ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 7.7ms\n",
            "Speed: 3.1ms preprocess, 7.7ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 7.4ms\n",
            "Speed: 4.1ms preprocess, 7.4ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 1 Hand_Raised, 9.8ms\n",
            "Speed: 4.5ms preprocess, 9.8ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 9.2ms\n",
            "Speed: 4.1ms preprocess, 9.2ms inference, 0.6ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 7.4ms\n",
            "Speed: 4.1ms preprocess, 7.4ms inference, 0.6ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 7.6ms\n",
            "Speed: 3.9ms preprocess, 7.6ms inference, 0.6ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 8.6ms\n",
            "Speed: 4.1ms preprocess, 8.6ms inference, 0.6ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 7.5ms\n",
            "Speed: 4.6ms preprocess, 7.5ms inference, 0.6ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 7.6ms\n",
            "Speed: 4.4ms preprocess, 7.6ms inference, 0.6ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 8.7ms\n",
            "Speed: 5.4ms preprocess, 8.7ms inference, 0.6ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 7.0ms\n",
            "Speed: 4.3ms preprocess, 7.0ms inference, 0.6ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 9.9ms\n",
            "Speed: 4.8ms preprocess, 9.9ms inference, 0.6ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 9.8ms\n",
            "Speed: 5.2ms preprocess, 9.8ms inference, 0.9ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 17.6ms\n",
            "Speed: 4.4ms preprocess, 17.6ms inference, 0.9ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 12.9ms\n",
            "Speed: 6.6ms preprocess, 12.9ms inference, 1.0ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 19.5ms\n",
            "Speed: 7.2ms preprocess, 19.5ms inference, 0.8ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 15.0ms\n",
            "Speed: 6.2ms preprocess, 15.0ms inference, 1.1ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 12.4ms\n",
            "Speed: 4.7ms preprocess, 12.4ms inference, 0.8ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 14.2ms\n",
            "Speed: 5.8ms preprocess, 14.2ms inference, 0.9ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 13.4ms\n",
            "Speed: 4.3ms preprocess, 13.4ms inference, 0.9ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 12.5ms\n",
            "Speed: 4.4ms preprocess, 12.5ms inference, 0.8ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 12.2ms\n",
            "Speed: 4.6ms preprocess, 12.2ms inference, 0.8ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 9.8ms\n",
            "Speed: 6.7ms preprocess, 9.8ms inference, 0.8ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 11.0ms\n",
            "Speed: 4.4ms preprocess, 11.0ms inference, 0.8ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 12.4ms\n",
            "Speed: 4.4ms preprocess, 12.4ms inference, 0.8ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 9.6ms\n",
            "Speed: 4.8ms preprocess, 9.6ms inference, 0.8ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 9.9ms\n",
            "Speed: 5.1ms preprocess, 9.9ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 15.2ms\n",
            "Speed: 4.2ms preprocess, 15.2ms inference, 0.8ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 15.1ms\n",
            "Speed: 5.2ms preprocess, 15.1ms inference, 1.5ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 9.3ms\n",
            "Speed: 4.2ms preprocess, 9.3ms inference, 0.7ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 8.9ms\n",
            "Speed: 4.4ms preprocess, 8.9ms inference, 0.7ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 8.5ms\n",
            "Speed: 4.8ms preprocess, 8.5ms inference, 0.7ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 16.0ms\n",
            "Speed: 4.7ms preprocess, 16.0ms inference, 0.9ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 12.7ms\n",
            "Speed: 4.4ms preprocess, 12.7ms inference, 2.7ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 11.8ms\n",
            "Speed: 5.6ms preprocess, 11.8ms inference, 0.8ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 8.9ms\n",
            "Speed: 5.0ms preprocess, 8.9ms inference, 0.8ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 15.5ms\n",
            "Speed: 4.6ms preprocess, 15.5ms inference, 0.9ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 9.3ms\n",
            "Speed: 4.2ms preprocess, 9.3ms inference, 0.7ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 11.4ms\n",
            "Speed: 5.3ms preprocess, 11.4ms inference, 0.8ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 8.7ms\n",
            "Speed: 5.0ms preprocess, 8.7ms inference, 0.7ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 11.5ms\n",
            "Speed: 9.5ms preprocess, 11.5ms inference, 0.7ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 11.8ms\n",
            "Speed: 4.8ms preprocess, 11.8ms inference, 0.8ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 13.5ms\n",
            "Speed: 5.0ms preprocess, 13.5ms inference, 0.9ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 14.8ms\n",
            "Speed: 5.3ms preprocess, 14.8ms inference, 0.7ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 9.6ms\n",
            "Speed: 4.4ms preprocess, 9.6ms inference, 0.7ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 8.9ms\n",
            "Speed: 4.9ms preprocess, 8.9ms inference, 0.7ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 10.0ms\n",
            "Speed: 4.3ms preprocess, 10.0ms inference, 0.7ms postprocess per image at shape (1, 3, 448, 768)\n",
            "\n",
            "0: 448x768 (no detections), 8.9ms\n",
            "Speed: 4.3ms preprocess, 8.9ms inference, 0.9ms postprocess per image at shape (1, 3, 448, 768)\n",
            "Processed video saved to /content/drive/MyDrive/Hand/output_video_with_person_identification.mp4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "z3tz4gmYWeRK"
      }
    }
  ]
}